{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Import successful\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import string\n",
    "import numpy as np\n",
    "import nltk\n",
    "import unidecode\n",
    "from collections import Counter\n",
    "from nltk import tokenize\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from scipy import spatial\n",
    "import gensim \n",
    "from gensim.models import Word2Vec\n",
    "from nltk.stem import SnowballStemmer\n",
    "from operator import itemgetter\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# From Utilities\n",
    "from utilities.pre_process_helpers import * \n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "stemmer = SnowballStemmer(\"english\")\n",
    "\n",
    "def preprocess(text, use_stemming=True):\n",
    "    \n",
    "    # TODO: Perform Name entity analysis first\n",
    "    \n",
    "    # Converting to Lower\n",
    "    text = str(text)\n",
    "    text = text.lower()\n",
    "    text = expand_contrations_driver(text)\n",
    "    text = remove_noise(text)\n",
    "    tokens = tokenize_word_text(text)\n",
    "    tokens = remove_accent(tokens)\n",
    "    tokens = remove_stopwords(tokens)\n",
    "    \n",
    "    # Stemming is used for Decriptions and not for the Name features\n",
    "    if use_stemming:\n",
    "        tokens = [stemmer.stem(token) for token in tokens]\n",
    "    return \" \".join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tfidf_model(documents, threshold=0.1):\n",
    "    tfidf_vectorizer = TfidfVectorizer(use_idf=True, max_df=0.4, ngram_range=(1,3))\n",
    "    tfidf_matrix = tfidf_vectorizer.fit_transform(documents)\n",
    "    # Tuning the tfidf model as per zipf law. \n",
    "    tf_df = pd.DataFrame(tfidf_matrix.toarray().T, index=tfidf_vectorizer.get_feature_names())\n",
    "    tf_df['tfidf'] = tf_df.max(axis=1)\n",
    "    temp = tf_df.drop(index=tf_df[tf_df.tfidf < threshold].index)\n",
    "    new_vocab = list(temp.index)\n",
    "    \n",
    "    # New tf model\n",
    "    tfidf_vectorizer_n = TfidfVectorizer(use_idf=True, vocabulary=new_vocab)\n",
    "    tfidf_matrix_n = tfidf_vectorizer_n.fit_transform(documents)\n",
    "    \n",
    "    return [tfidf_vectorizer_n, tfidf_matrix_n]\n",
    "\n",
    "\n",
    "WORD_VECTOR_SIZE = 50\n",
    "MIN_COUNT = 1\n",
    "WINDOW = 7\n",
    "def get_word2vec_model(documents):\n",
    "    documents = [document.split() for document in documents]\n",
    "    word2vec_model = gensim.models.Word2Vec(documents, min_count = MIN_COUNT, \\\n",
    "                                             size = WORD_VECTOR_SIZE, window = WINDOW, iter=3)\n",
    "    document_matrix = []\n",
    "    for document in documents:\n",
    "        document_matrix.append(get_doc2vec_vector(word2vec_model, \" \".join(document)))\n",
    "    return word2vec_model, np.array(document_matrix)\n",
    "    \n",
    "def get_doc2vec_vector(model, doc):\n",
    "    doc_vec = [0]*WORD_VECTOR_SIZE\n",
    "    num_skip = 0\n",
    "    for word in doc:\n",
    "        try:\n",
    "            doc_vec = np.add(doc_vec, model[word])\n",
    "        except (KeyError):\n",
    "            # If word does not exist in dictionary then give 0.01 weight to it for all dimension\n",
    "            num_skip += 1\n",
    "    return np.asarray(doc_vec)/(len(doc)-num_skip)\n",
    "\n",
    "\n",
    "def get_name_features(names):\n",
    "    name_vectorizer = CountVectorizer()\n",
    "    transformed = name_vectorizer.fit_transform(names)\n",
    "    name_features = transformed.toarray()\n",
    "    return name_vectorizer, name_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_total_score(tf_score, embed_score):\n",
    "    return tf_score+embed_score\n",
    "\n",
    "def cosine_score(doc, query):\n",
    "    return 1 - spatial.distance.cosine(doc, query)\n",
    "#     return np.sum(np.multiply(doc, query))\n",
    "\n",
    "def get_cosine_nearest_documents(embed_q_vec, tf_q_vec, tfidf_features, embed_features, TOTAL_DOCS):\n",
    "    cos_scores = []\n",
    "    for doc_index in range(TOTAL_DOCS):\n",
    "        score1 = cosine_score(embed_features[doc_index], embed_q_vec)\n",
    "        score2 = cosine_score(tfidf_features[doc_index].reshape(1, tfidf_features.shape[1]), tf_q_vec)\n",
    "        cos_scores.append([score1, score2])\n",
    "    return pd.DataFrame(cos_scores, columns=['string_match', 'embedd_match'])\n",
    "\n",
    "def get_query_related_tool(name_features, query_vector):\n",
    "    similar_score = -1\n",
    "    similar_index = -1\n",
    "\n",
    "    for index in range(len(name_features)):\n",
    "        sim_score = cosine_similarity(name_features[index].reshape((1, -1)), query_vector)[0][0]\n",
    "        if similar_score <= sim_score:\n",
    "            similar_index = index\n",
    "            similar_score = sim_score\n",
    "            \n",
    "    return [similar_index, similar_score]\n",
    "\n",
    "def query_synthesizer(query, tfidf_vectorizer, embed_vectorizer):\n",
    "    # Applying same pre-processing on query\n",
    "    query = preprocess(query)\n",
    "    # print(\"Query: \"+str(query.split()))\n",
    "    \n",
    "    # Creating feature vector of query. Feature vector creation should be same as of Documents\n",
    "    tfidf_query_vector = tfidf_vectorizer.transform([query])\n",
    "    embedd_query_vector = get_doc2vec_vector(embed_vectorizer, query)\n",
    "    \n",
    "    return [embedd_query_vector, tfidf_query_vector.toarray()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making data better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def category_filter(category):\n",
    "    category = category.lower()\n",
    "    category = category.split(\",\")[0]\n",
    "    category = category.strip()\n",
    "    category = str(category)\n",
    "    \n",
    "    if 'crm' in category or 'market' in category:\n",
    "        category = 'crm software'\n",
    "    elif 'erp' in category:\n",
    "        category = 'erp software'\n",
    "    elif 'business' in category:\n",
    "        category = 'business intelligence software'\n",
    "    elif 'dashboard' in category:\n",
    "        category = 'dashboard'\n",
    "    elif ('project') in category:\n",
    "        category = 'project management software'\n",
    "    elif ('product') in category or ('inventory') in category or ('plm') in category:  \n",
    "        category = 'inventory or product management software'\n",
    "    elif ('analys') in category or ('analytic') in category or ('visual') in category:\n",
    "        category = 'predictive analytics software'\n",
    "    elif ('supply') in category or ('scm') in category:\n",
    "        category = 'supply chain management software'\n",
    "    elif ('procurement') in category:\n",
    "        category = 'procurement management software'\n",
    "    elif ('task') in category or ('tms soft') in category:\n",
    "        category = 'task management software'\n",
    "        \n",
    "    return category"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tuning Tf-idf model"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Removing terms which appears more than 50% of the documents\n",
    "tfidf_vectorizer_x = TfidfVectorizer(use_idf=True, max_df=0.5)\n",
    "tfidf_matrix_x = tfidf_vectorizer_x.fit_transform(df.desc_preprocess)\n",
    "feature_2 = tfidf_vectorizer_x.get_feature_names()\n",
    "\n",
    "print(\"Shape: \"+ str(tfidf_matrix_x.shape))\n",
    "# Tuning the tfidf model as per zipf law. \n",
    "tf_df = pd.DataFrame(tfidf_matrix_x.toarray().T, index=tfidf_vectorizer_x.get_feature_names())\n",
    "tf_df['tfidf'] = tf_df.max(axis=1)\n",
    "# min_threshold = 0.04\n",
    "# print(tf_df[tf_df.tfidf < min_threshold])\n",
    "max_threshold = 0.75\n",
    "tf_df[tf_df.tfidf > max_threshold]\n",
    "\n",
    "\n",
    "# threshold = 0.00\n",
    "# for i in range(20):\n",
    "#     print(\"Threshold: %.3f -> %d\"%(threshold, tf_df[tf_df.tfidf < threshold].shape[0]))\n",
    "#     threshold += 0.01\n",
    "# temp = tf_df.drop(index=tf_df[tf_df.tfidf < 0.05].index)\n",
    "# new_vocab = list(temp.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "def dump_vectors(tfidf_matrix, wordvec_matrix):\n",
    "    '''\n",
    "    Exports the calculated matrices in pickle dataset for further use. \n",
    "    It saves a lot of learning time. Just load then and calculate proximity with query with the vectors\n",
    "    To load learnt features use below code:\n",
    "    data = pickle.load(open(\"data/features_v1.pkl\", \"rb\"))\n",
    "    \n",
    "    @input\n",
    "    tfidf_matrix -> Learnt Tf-Idf matrix based on dataset given\n",
    "    word2vec_matrix -> Learnt Word2Vec matrix based on dataset given\n",
    "    '''\n",
    "    \n",
    "    PIK_FILE = \"data/features_v1.pkl\"\n",
    "    data = {}\n",
    "    data['tfidf'] = tfidf_matrix\n",
    "    data['word2vec'] = wordvec_matrix\n",
    "    \n",
    "    pickle.dump(data, open(PIK_FILE, 'wb+'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Script for Reading CSV data and dropping duplicate name tools \n",
    "temp_df = pd.read_csv(\"data/Alter.csv\")\n",
    "temp_df = temp_df.drop_duplicates(subset=['name'], keep='first')\n",
    "temp_df.to_csv(\"data/new_data_v1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/new_data_v1.csv\", index_col=0)\n",
    "df.reset_index(inplace=True)\n",
    "df.drop(['index'], axis=1, inplace=True)\n",
    "df_copy = df.copy()\n",
    " \n",
    "# Performing pre-process. Output -> tokens separated by space\n",
    "df.description = df.description + \" \" + df.license\n",
    "df.desc_preprocess = df.description.apply(preprocess)\n",
    "\n",
    "# Not using new categories\n",
    "# df['cat_new'] = df.category.apply(category_filter)\n",
    "\n",
    "# Getting feature vector\n",
    "## Getting Tf-Idf feature vector\n",
    "tfidf_vectorizer, tfidf_matrix = get_tfidf_model(df.desc_preprocess)\n",
    "tfidf_features = tfidf_matrix.toarray()\n",
    "\n",
    "## Getting word-2-vec feature vector\n",
    "embed_vectorizer, embed_features = get_word2vec_model(df.desc_preprocess)\n",
    "\n",
    "TOTAL_DOCS = 0\n",
    "if(embed_features.shape[0] == tfidf_features.shape[0]):\n",
    "    TOTAL_DOCS = embed_features.shape[0]\n",
    "else:\n",
    "    print(\"Tf-Idf and Embedding feature shapes are different\")\n",
    "\n",
    "# Getting Name features\n",
    "df['name_preprocess'] = df.apply(lambda row: preprocess(row['name'], False), axis=1)\n",
    "name_vectorizer, name_features = get_name_features(df.name_preprocess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Handling Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query match with tool: 'ECount ERP', with score: 0.7071067811865475\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>embedd_match</th>\n",
       "      <th>string_match</th>\n",
       "      <th>total_score</th>\n",
       "      <th>pricing</th>\n",
       "      <th>users</th>\n",
       "      <th>license</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>95</td>\n",
       "      <td>Jeeves ERP</td>\n",
       "      <td>0.482246</td>\n",
       "      <td>0.999876</td>\n",
       "      <td>1.482122</td>\n",
       "      <td>Subscription</td>\n",
       "      <td>Small (1001 employees)</td>\n",
       "      <td>Proprietary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>93</td>\n",
       "      <td>Orion ERP</td>\n",
       "      <td>0.305936</td>\n",
       "      <td>0.999672</td>\n",
       "      <td>1.305608</td>\n",
       "      <td>Subscription</td>\n",
       "      <td>Small (1001 employees)</td>\n",
       "      <td>Proprietary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>92</td>\n",
       "      <td>NetSuite ERP</td>\n",
       "      <td>0.256210</td>\n",
       "      <td>0.999594</td>\n",
       "      <td>1.255804</td>\n",
       "      <td>Subscription</td>\n",
       "      <td>Small (1001 employees)</td>\n",
       "      <td>Proprietary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>91</td>\n",
       "      <td>Brightpearl</td>\n",
       "      <td>0.142586</td>\n",
       "      <td>0.999774</td>\n",
       "      <td>1.142360</td>\n",
       "      <td>Subscription</td>\n",
       "      <td>Small (1001 employees)</td>\n",
       "      <td>Proprietary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>98</td>\n",
       "      <td>Oracle ERP Cloud</td>\n",
       "      <td>0.110647</td>\n",
       "      <td>0.999752</td>\n",
       "      <td>1.110399</td>\n",
       "      <td>Subscription</td>\n",
       "      <td>Small (1001 employees)</td>\n",
       "      <td>Proprietary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>84</td>\n",
       "      <td>Zycus Procure to Pay</td>\n",
       "      <td>0.093071</td>\n",
       "      <td>0.999723</td>\n",
       "      <td>1.092795</td>\n",
       "      <td>Subscription</td>\n",
       "      <td>Small (1001 employees)</td>\n",
       "      <td>Proprietary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>141</td>\n",
       "      <td>AIMMS</td>\n",
       "      <td>0.078926</td>\n",
       "      <td>0.999884</td>\n",
       "      <td>1.078810</td>\n",
       "      <td>Subscription</td>\n",
       "      <td>Small (1001 employees)</td>\n",
       "      <td>Proprietary Software</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>RF-SMART</td>\n",
       "      <td>0.061200</td>\n",
       "      <td>0.999808</td>\n",
       "      <td>1.061007</td>\n",
       "      <td>Subscription</td>\n",
       "      <td>Small (1001 employees)</td>\n",
       "      <td>Proprietary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>EazyStock</td>\n",
       "      <td>0.044373</td>\n",
       "      <td>0.999784</td>\n",
       "      <td>1.044157</td>\n",
       "      <td>Subscription</td>\n",
       "      <td>Small (1001 employees)</td>\n",
       "      <td>Proprietary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>81</td>\n",
       "      <td>JAGGAER Procure to Pay</td>\n",
       "      <td>0.040603</td>\n",
       "      <td>0.999715</td>\n",
       "      <td>1.040318</td>\n",
       "      <td>Subscription</td>\n",
       "      <td>Small (1001 employees)</td>\n",
       "      <td>Proprietary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>MPO TMS</td>\n",
       "      <td>0.040004</td>\n",
       "      <td>0.999793</td>\n",
       "      <td>1.039797</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Small (1001 employees)</td>\n",
       "      <td>Proprietary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>89</td>\n",
       "      <td>Basware Procure to Pay</td>\n",
       "      <td>0.036803</td>\n",
       "      <td>0.999769</td>\n",
       "      <td>1.036572</td>\n",
       "      <td>Subscription</td>\n",
       "      <td>Small (1001 employees)</td>\n",
       "      <td>Proprietary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>Fishbowl</td>\n",
       "      <td>0.029618</td>\n",
       "      <td>0.999802</td>\n",
       "      <td>1.029420</td>\n",
       "      <td>Subscription</td>\n",
       "      <td>Small (1001 employees)</td>\n",
       "      <td>Proprietary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>85</td>\n",
       "      <td>Coupa Procure to Pay</td>\n",
       "      <td>0.029575</td>\n",
       "      <td>0.999650</td>\n",
       "      <td>1.029224</td>\n",
       "      <td>Subscription</td>\n",
       "      <td>Small (1001 employees)</td>\n",
       "      <td>Proprietary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>57</td>\n",
       "      <td>Seal Report</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.999925</td>\n",
       "      <td>0.999925</td>\n",
       "      <td>Subscription</td>\n",
       "      <td>Small (1001 employees)</td>\n",
       "      <td>Open Source</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>Orderhive</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.999910</td>\n",
       "      <td>0.999910</td>\n",
       "      <td>Subscription</td>\n",
       "      <td>Small (1001 employees)</td>\n",
       "      <td>Proprietary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>54</td>\n",
       "      <td>iDashboards</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.999909</td>\n",
       "      <td>0.999909</td>\n",
       "      <td>Subscription</td>\n",
       "      <td>Small (1001 employees)</td>\n",
       "      <td>Proprietary Software</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>74</td>\n",
       "      <td>JReport</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.999903</td>\n",
       "      <td>0.999903</td>\n",
       "      <td>Subscription</td>\n",
       "      <td>Small (1001 employees)</td>\n",
       "      <td>Proprietary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>59</td>\n",
       "      <td>ReportServer Community Edition</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.999900</td>\n",
       "      <td>0.999900</td>\n",
       "      <td>Subscription</td>\n",
       "      <td>Small (1001 employees)</td>\n",
       "      <td>Open Source</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>62</td>\n",
       "      <td>Profisee</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.999886</td>\n",
       "      <td>0.999886</td>\n",
       "      <td>Subscription</td>\n",
       "      <td>Small (1000 employees)</td>\n",
       "      <td>Proprietary Software</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               name  embedd_match  string_match  total_score  \\\n",
       "95                       Jeeves ERP      0.482246      0.999876     1.482122   \n",
       "93                        Orion ERP      0.305936      0.999672     1.305608   \n",
       "92                     NetSuite ERP      0.256210      0.999594     1.255804   \n",
       "91                      Brightpearl      0.142586      0.999774     1.142360   \n",
       "98                 Oracle ERP Cloud      0.110647      0.999752     1.110399   \n",
       "84             Zycus Procure to Pay      0.093071      0.999723     1.092795   \n",
       "141                           AIMMS      0.078926      0.999884     1.078810   \n",
       "12                         RF-SMART      0.061200      0.999808     1.061007   \n",
       "15                        EazyStock      0.044373      0.999784     1.044157   \n",
       "81           JAGGAER Procure to Pay      0.040603      0.999715     1.040318   \n",
       "23                          MPO TMS      0.040004      0.999793     1.039797   \n",
       "89           Basware Procure to Pay      0.036803      0.999769     1.036572   \n",
       "19                         Fishbowl      0.029618      0.999802     1.029420   \n",
       "85             Coupa Procure to Pay      0.029575      0.999650     1.029224   \n",
       "57                      Seal Report      0.000000      0.999925     0.999925   \n",
       "17                        Orderhive      0.000000      0.999910     0.999910   \n",
       "54                      iDashboards      0.000000      0.999909     0.999909   \n",
       "74                          JReport      0.000000      0.999903     0.999903   \n",
       "59   ReportServer Community Edition      0.000000      0.999900     0.999900   \n",
       "62                         Profisee      0.000000      0.999886     0.999886   \n",
       "\n",
       "          pricing                   users               license  \n",
       "95   Subscription  Small (1001 employees)           Proprietary  \n",
       "93   Subscription  Small (1001 employees)           Proprietary  \n",
       "92   Subscription  Small (1001 employees)           Proprietary  \n",
       "91   Subscription  Small (1001 employees)           Proprietary  \n",
       "98   Subscription  Small (1001 employees)           Proprietary  \n",
       "84   Subscription  Small (1001 employees)           Proprietary  \n",
       "141  Subscription  Small (1001 employees)  Proprietary Software  \n",
       "12   Subscription  Small (1001 employees)           Proprietary  \n",
       "15   Subscription  Small (1001 employees)           Proprietary  \n",
       "81   Subscription  Small (1001 employees)           Proprietary  \n",
       "23            NaN  Small (1001 employees)           Proprietary  \n",
       "89   Subscription  Small (1001 employees)           Proprietary  \n",
       "19   Subscription  Small (1001 employees)           Proprietary  \n",
       "85   Subscription  Small (1001 employees)           Proprietary  \n",
       "57   Subscription  Small (1001 employees)           Open Source  \n",
       "17   Subscription  Small (1001 employees)           Proprietary  \n",
       "54   Subscription  Small (1001 employees)  Proprietary Software  \n",
       "74   Subscription  Small (1001 employees)           Proprietary  \n",
       "59   Subscription  Small (1001 employees)           Open Source  \n",
       "62   Subscription  Small (1000 employees)  Proprietary Software  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_string = \"ERP\"\n",
    "\n",
    "# Check if Query has exact match with database\n",
    "name_query_vector = name_vectorizer.transform([preprocess(query_string, False)])\n",
    "q_sim_index, q_sim_score = get_query_related_tool(name_features, name_query_vector)\n",
    "# If cosine similarity score is high then change query to that document\n",
    "if q_sim_score > 0.8:\n",
    "    query = df.loc[q_sim_index]['description']\n",
    "else:\n",
    "    query = query_string\n",
    "    \n",
    "print(\"Query match with tool: '{}', with score: {}\".format(df.loc[q_sim_index]['name'], q_sim_score))\n",
    "    \n",
    "embed_q_vec, tf_q_vec = query_synthesizer(query, tfidf_vectorizer, embed_vectorizer)\n",
    "\n",
    "# Finding Cosine similarity between Documents and Query\n",
    "cos_score = get_cosine_nearest_documents(embed_q_vec, tf_q_vec, tfidf_features, embed_features, TOTAL_DOCS)\n",
    "result = df.join(cos_score)\n",
    "result = result.sort_values(by=['embedd_match', 'string_match'], ascending=False)\n",
    "\n",
    "# Printing Similar documents. Top 20\n",
    "total_results = 20\n",
    "# Filter out SAP products\n",
    "result = result[result.name.str.contains(\"SAP\") == False]\n",
    "result = result[result.name != df.loc[q_sim_index]['name']]\n",
    "result['total_score'] = result['embedd_match'] + result['string_match']\n",
    "result[['name', 'embedd_match', 'string_match', 'total_score', 'pricing', 'users','license']][:total_results]\\\n",
    "    .sort_values(by=['total_score'], ascending=[False])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Future work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (Not Using) KD Tree\n",
    "##### Substitute of knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KDTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = tfidf_features.tolist()\n",
    "b = embed_features.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "kdt_tf = KDTree(a, leaf_size=10)\n",
    "kdt_embed = KDTree(b, leaf_size=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "# For Tf-Idf \n",
    "dist, idx = kdt_tf.query(tf_q_vec, k=10)\n",
    "\n",
    "# For Word2Vec\n",
    "dist_1, idx_1 = kdt_embed.query(embed_q_vec.reshape([1, embed_q_vec.shape[0]]), k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Abbreviation extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_abbreviated_terms(text):\n",
    "    # matches = re.findall(r'(?:(?<=^)|(?<=[^.]))\\s+([A-Z]{2,})', text)\n",
    "    matches = re.findall(r'\\b[A-Z]{2,}\\b', text)\n",
    "    return list(set(matches))\n",
    "\n",
    "# df_copy['abbr'] = df_copy.description.apply(get_abbreviated_terms)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:light"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
